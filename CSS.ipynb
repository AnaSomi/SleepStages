{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import plotly.graph_objects as go \n",
    "import mne\n",
    "from gtda.diagrams import Scaler, BettiCurve\n",
    "from sklearn.decomposition import PCA\n",
    "from gtda.time_series import TakensEmbedding\n",
    "from gtda.time_series import takens_embedding_optimal_parameters, SlidingWindow\n",
    "from gtda.plotting import plot_point_cloud\n",
    "import plotly.graph_objects as go \n",
    "import numpy as np\n",
    "from gtda.homology import VietorisRipsPersistence, WeakAlphaPersistence\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, plot,iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(num_subject):\n",
    "    return np.unique(sheetX[(sheetX.subject == num_subject)]['age'].tolist())[0]\n",
    "def get_time(num_subject, num_night):\n",
    "    return np.unique(sheetX[(sheetX.subject == num_subject) & (sheetX.night == num_night)]['LightsOff'].tolist())[0]\n",
    "def get_gender(num_subject):\n",
    "    return np.unique(sheetX[(sheetX.subject == num_subject)][\"sex (F=1)\"].tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.diagrams import PersistenceLandscape\n",
    "def get_land(n, name):\n",
    "  PL = PersistenceLandscape(n_layers=1, n_bins=100, n_jobs = -1)\n",
    "  temp = PL.fit_transform(get_diag(n, name))\n",
    "  fig = PL.plot(temp, homology_dimensions=[1])\n",
    "  av = PL.plot(temp, homology_dimensions=[0])\n",
    "  fig.add_trace(av['data'][0], row=1, col=1)\n",
    "  fig.show()\n",
    "  #fig = PI.plot(temp, homology_dimensions=1)\n",
    "  #fig.show()\n",
    "  return temp\n",
    "  #fig.write_image(f'1.pdf') \n",
    "  #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.diagrams import PersistenceImage\n",
    "def get_image(aw):\n",
    "  PI = PersistenceImage(sigma=0.03, n_bins=500, n_jobs = -1)\n",
    "  temp = PI.fit_transform(aw)\n",
    "  fig = PI.plot(temp, homology_dimension_idx=0)\n",
    "\n",
    "  fig.show()\n",
    "  fig = PI.plot(temp, homology_dimension_idx=1)\n",
    "  fig.show()\n",
    "  return temp\n",
    "  #fig.write_image(f'1.pdf') \n",
    "  #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diag(raw_n, n, name): \n",
    "  print(name)\n",
    "  y = raw_n['EEG Fpz-Cz'][1][n * 100 :n * 100 + 100 * 30 + 1]\n",
    "  x = raw_n['EEG Fpz-Cz'][0][0][n * 100:n * 100 + 100 * 30 + 1]\n",
    "  data = np.hstack((np.array(x), np.array(y)))\n",
    "  optimal_time_delay,optimal_embedding_dimension = takens_embedding_optimal_parameters(data, 300, 5, stride=1) \n",
    "  TE = TakensEmbedding(\n",
    "    time_delay=optimal_time_delay,\n",
    "    dimension=optimal_embedding_dimension,\n",
    "    stride = 1\n",
    "  )\n",
    "  window_size = 3000 \n",
    "\n",
    "  window_stride = 2 \n",
    "\n",
    "  SW = SlidingWindow(size=window_size, stride=window_stride) \n",
    "\n",
    "  X_windows, y_windows = SW.fit_transform_resample(x, y) \n",
    "  homology_dimensions = [0, 1]\n",
    "  y_nonperiodic_embedded = TE.fit_transform(X_windows)\n",
    "  WA = VietorisRipsPersistence(\n",
    "    homology_dimensions=homology_dimensions, n_jobs=-1\n",
    "  )\n",
    "  aw = WA.fit_transform(y_nonperiodic_embedded)\n",
    "  \n",
    "  if aw[0][len(aw) - 1][0] == aw[0][len(aw) - 1][1]:\n",
    "        aw[0] = aw[0][:len(aw) - 1]\n",
    "\n",
    "  diagramScaler = Scaler()\n",
    "  X_scaled = diagramScaler.fit_transform(aw)\n",
    "  return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_cop = np.zeros((100000, 34))\n",
    "STAT = np.zeros((100000, 34))\n",
    "from scipy.signal import find_peaks\n",
    "def get_statistics(raw_n, n, aw, name, j):\n",
    "  M1 = []\n",
    "  M0 = []\n",
    "  L1 = []\n",
    "  L0 = []\n",
    "  for i in range(len(aw[0])):\n",
    "    if aw[0][i][2] == 1.:\n",
    "      if abs(aw[0][i][0] - aw[0][i][1]) < 0.005:\n",
    "        continue\n",
    "      M1.append((aw[0][i][0] + aw[0][i][1]) / 2)\n",
    "      L1.append(aw[0][i][1] - aw[0][i][0])\n",
    "    else:\n",
    "      if abs(aw[0][i][0] - aw[0][i][1]) < 0.005:\n",
    "        continue\n",
    "      M0.append((aw[0][i][0] + aw[0][i][1]) / 2)\n",
    "      L0.append(aw[0][i][1] - aw[0][i][0])\n",
    "  ST = np.vstack((np.array(M0),np.array(L0)))\n",
    "  ST1 = np.vstack((np.array(M1), np.array(L1)))\n",
    "  #print(ST)\n",
    "  #print(ST1)\n",
    "  k = 0\n",
    "  for i in range(2):\n",
    "    arr = np.array(ST[i])\n",
    "    summ = np.sum(arr)\n",
    "    STAT[j][0 + k] =np.mean(arr)\n",
    "    STAT[j][1 + k] =np.std(arr)\n",
    "    STAT[j][4 + k] = np.quantile(arr, 0.25, axis=0)\n",
    "    STAT[j][5 + k] = np.quantile(arr, 0.5, axis=0)\n",
    "    STAT[j][6 + k] = np.quantile(arr, 0.75, axis=0)\n",
    "    STAT[j][2 + k] = scipy.stats.skew(arr)\n",
    "    STAT[j][3 + k] = scipy.stats.kurtosis(arr)\n",
    "    STAT[j][7 + k] = np.sum((-arr/summ) * np.log(arr/summ))\n",
    "    k = 8\n",
    "  k += 8\n",
    "  for i in range(2):\n",
    "    arr = np.array(ST1[i])\n",
    "    #print(arr)\n",
    "    summ = np.sum(arr)\n",
    "    STAT[j][0 + k] =np.mean(arr)\n",
    "    STAT[j][1 + k] =np.std(arr)\n",
    "    STAT[j][4 + k] = np.quantile(arr, 0.25, axis=0)\n",
    "    STAT[j][5 + k] = np.quantile(arr, 0.5, axis=0)\n",
    "    STAT[j][6 + k] = np.quantile(arr, 0.75, axis=0)\n",
    "    STAT[j][2 + k] = scipy.stats.skew(arr)\n",
    "    STAT[j][3 + k] = scipy.stats.kurtosis(arr)\n",
    "    STAT[j][7 + k] = np.sum((-arr/summ) * np.log(arr/summ))\n",
    "    k += 8\n",
    "  \n",
    "  yf = np.fft.fft(raw_n['EEG Fpz-Cz'][0][0][n * 100 :n * 100 + 100 * 30 + 1]).real\n",
    "  peaks_index, properties = find_peaks(np.abs(yf), height=0.005)\n",
    "  for i in range(len(peaks_index)):\n",
    "    if (i % 2 == 0):\n",
    "      if i + 1 < len(peaks_index):\n",
    "        STAT[j][33] = max(STAT[j][33], peaks_index[i + 1] - peaks_index[i])\n",
    "  STAT[j][32] = name\n",
    "  ST_cop = STAT.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "PATH = \"Datasets/sleep-edf-database-expanded-1.0.0/sleep-cassette/\"\n",
    "subjects = [i for i in range(83)]\n",
    "train, test = train_test_split(subjects, test_size = 0.3, random_state=42)\n",
    "xls = pd.ExcelFile(r\"Datasets/sleep-edf-database-expanded-1.0.0/SC-subjects.xls\")\n",
    "sheetX = xls.parse(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "PATH = \"Datasets/sleep-edf-database-expanded-1.0.0/sleep-cassette/\"\n",
    "subjects = [i for i in range(83)]\n",
    "train, test = train_test_split(subjects, test_size = 0.3, random_state=23)\n",
    "xls = pd.ExcelFile(r\"Datasets/sleep-edf-database-expanded-1.0.0/SC-subjects.xls\")\n",
    "sheetX = xls.parse(0)\n",
    "\n",
    "for i in test:\n",
    "    for j in range(1, 3):\n",
    "        print(i, j)\n",
    "        if i == 13 and j == 2:\n",
    "            break\n",
    "        num_sub = str(i)\n",
    "        if i < 10:\n",
    "            num_sub = '0' + str(i)\n",
    "        prefixed = [filename for filename in os.listdir(PATH) if filename.startswith(\"SC4\" + num_sub + str(j))]\n",
    "        raw = mne.io.read_raw_edf(PATH + prefixed[0], preload=True) \n",
    "        annot = mne.read_annotations(PATH + prefixed[1])\n",
    "        annotation_desc_2_event_id = {'Sleep stage W': 1, 'Sleep stage 1': 2, 'Sleep stage 2': 3,'Sleep stage 3': 4,'Sleep stage 4': 5, 'Sleep stage R': 6}\n",
    "        if get_time(i,j).hour > 8:\n",
    "            annot.crop(annot[1]['onset'] - 30 * 60, annot[-2]['onset'] + 30 * 60)\n",
    "        raw_n = raw.copy()\n",
    "        raw_filt = raw_n.copy().filter(0.1, 30)\n",
    "        raw_n = raw_filt.copy() \n",
    "        event_id = {'Sleep stage W': 1,'Sleep stage 1': 2,'Sleep stage 2': 3,'Sleep stage 3': 4,'Sleep stage 4': 5,'Sleep stage R': 6} \n",
    "        raw_n.set_annotations(annot, emit_warning=False) \n",
    "        events, _ = mne.events_from_annotations(raw_n, event_id=annotation_desc_2_event_id, chunk_duration=30.)\n",
    "        #fig = mne.viz.plot_events(events, event_id=event_id,sfreq=raw.info['sfreq'],first_samp=events[0, 0], on_missing='ignore')\n",
    "        #stage_colors = plt.rcParams['axes.prop_cycle'].by_key()['color'] \n",
    "        #plt.savefig('Stages_' + str(i) + '_' + str(j) + '.png')\n",
    "        tmax = 30. - 1. / raw_n.info['sfreq']\n",
    "        epochs_train = mne.Epochs(raw=raw_n, events=events,\n",
    "                                  event_id=event_id, tmin=0., tmax=tmax, baseline=None, on_missing='ignore')\n",
    "        id_e = 0\n",
    "        for event_id in events:\n",
    "            ans = get_diag(raw_n, event_id[0] // 100, event_id[2])\n",
    "            #print('ans: ', ans)\n",
    "            get_statistics(raw_n, event_id[0] // 100, ans, event_id[2], id_e)\n",
    "            id_e += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT = np.copy(DO_NOT_TOUCH[:1000])\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def get_data():\n",
    "    dataset = pd.DataFrame({'STAGE': STAT[:, 32], 'MEAN_M0': STAT[:, 0], 'STD_M0': STAT[:, 1], 'stew_M0': STAT[:, 2], 'kurtosis_M0': STAT[:, 3],\n",
    "                            '25_M0': STAT[:, 4], '50_M0': STAT[:, 5], '75_M0': STAT[:, 6], 'ENT_M0': STAT[:, 7],\n",
    "                            'MEAN_L0': STAT[:, 8], 'STD_L0': STAT[:, 9], 'stew_L0': STAT[:, 10], 'kurtosis_L0': STAT[:, 11],\n",
    "                            '25_L0': STAT[:, 12], '50_L0': STAT[:, 13], '75_L0': STAT[:, 14], 'ENT_L0': STAT[:, 15],\n",
    "                            'MEAN_M1': STAT[:, 16], 'STD_M1': STAT[:, 17], 'stew_M1': STAT[:, 18], 'kurtosis_M1': STAT[:, 19],\n",
    "                            '25_M1': STAT[:, 20], '50_M1': STAT[:,21], '75_M1': STAT[:, 22], 'ENT_M1': STAT[:, 23],\n",
    "                            'MEAN_L1': STAT[:, 24], 'STD_L1': STAT[:, 25], 'stew_L1': STAT[:, 26], 'kurtosis_L1': STAT[:, 27],\n",
    "                            '25_L1': STAT[:, 28], '50_L1': STAT[:, 29], '75_L1': STAT[:, 30], 'ENT_L1': STAT[:, 31],\n",
    "                          'FFT': STAT[:, 33]})\n",
    "    return dataset\n",
    "dataset = get_data()\n",
    "from sklearn.svm import LinearSVC\n",
    "y = dataset['STAGE']\n",
    "y = label_binarize(y, classes=[1, 2, 3, 4, 5, 6])\n",
    "n_classes = y.shape[1]\n",
    "X = dataset.drop(columns='STAGE')\n",
    "clf = OneVsRestClassifier(\n",
    "    svm.SVC(kernel=\"linear\", probability=True, random_state=0)\n",
    ")\n",
    "y_score = (clf.fit(X, y).decision_function(X))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
